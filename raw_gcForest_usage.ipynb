{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victormayowa/deepFECG/blob/notebook/raw_gcForest_usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUBXXLzbs7gx"
      },
      "source": [
        "# Deep FECG Research: All-in-One Experiment Notebook for Google Colab\n",
        "\n",
        "This notebook is optimized for Python 3.12+ and modern libraries in a Google Colab environment. It contains all the code for data preprocessing, feature extraction, and model training using a self-contained `gcForest` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RKYW5fcs7g0"
      },
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "This cell installs all necessary libraries. Run it first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_CpU3Z4s7g0",
        "outputId": "64f45a33-a422-43fc-b2eb-946e00830f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.7/127.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q wfdb librosa pywavelets ssqueezepy imbalanced-learn shap matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjSk9-Ues7g2"
      },
      "source": [
        "## 2. Mount Google Drive & Define Paths\n",
        "\n",
        "This section mounts your Google Drive to make your dataset accessible. You will need to authorize Colab to access your Drive.\n",
        "\n",
        "**IMPORTANT:** After running the second cell, you **must** update the `PROJECT_PATH` variable to point to the correct location of your project folder on Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cFllUm6s7g2",
        "outputId": "0d38f795-b87b-448c-bf8c-147f84870906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i2MmKOgs7g2",
        "outputId": "550786ad-3b22-46c1-d7c9-34e3e83a0ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project path set to: /content/drive/MyDrive/MScUEL\n",
            "Data path set to: /content/drive/MyDrive/MScUEL/mit-bih-arrhythmia-database-1.0.0\n",
            "Output path set to: /content/drive/MyDrive/MScUEL/colab_outputs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# TODO: Update this path to your project directory on Google Drive\n",
        "PROJECT_PATH = '/content/drive/MyDrive/MScUEL'\n",
        "\n",
        "# --- You should not need to edit below this line ---\n",
        "DATA_PATH = os.path.join(PROJECT_PATH, 'mit-bih-arrhythmia-database-1.0.0')\n",
        "OUTPUT_PATH = os.path.join(PROJECT_PATH, 'colab_outputs')\n",
        "\n",
        "# Create an output directory for plots if it doesn't exist\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Project path set to: {PROJECT_PATH}\")\n",
        "print(f\"Data path set to: {DATA_PATH}\")\n",
        "print(f\"Output path set to: {OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl0CY2B5s7g3"
      },
      "source": [
        "## 3. All-in-One Experiment Code\n",
        "\n",
        "The following cells contain all the necessary code for the experiment pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJA5_HlNs7g3"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class gcForest(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, shape_1X=None, n_mgsRFtree=30, window=None, stride=1,\n",
        "                 cascade_test_size=0.2, n_cascadeRF=2, n_cascadeRFtree=101, cascade_layer=np.inf,\n",
        "                 min_samples_mgs=0.1, min_samples_cascade=0.05, tolerance=0.0, n_jobs=1, use_mg_scanning=True):\n",
        "        self.shape_1X = shape_1X\n",
        "        self.n_layer = 0\n",
        "        self._n_samples = 0\n",
        "        self.n_cascadeRF = int(n_cascadeRF)\n",
        "        self.window = [window] if isinstance(window, int) else window\n",
        "        self.stride = stride\n",
        "        self.cascade_test_size = cascade_test_size\n",
        "        self.n_mgsRFtree = int(n_mgsRFtree)\n",
        "        self.n_cascadeRFtree = int(n_cascadeRFtree)\n",
        "        self.cascade_layer = cascade_layer\n",
        "        self.min_samples_mgs = min_samples_mgs\n",
        "        self.min_samples_cascade = min_samples_cascade\n",
        "        self.tolerance = tolerance\n",
        "        self.n_jobs = n_jobs\n",
        "        self.use_mg_scanning = use_mg_scanning\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if X.shape[0] != len(y):\n",
        "            raise ValueError('Sizes of y and X do not match.')\n",
        "        if self.use_mg_scanning:\n",
        "            X = self.mg_scanning(X, y)\n",
        "        self.cascade_forest(X, y)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if self.use_mg_scanning:\n",
        "            X = self.mg_scanning(X)\n",
        "        cascade_all_pred_prob = self.cascade_forest(X)\n",
        "        return np.mean(cascade_all_pred_prob, axis=0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred_proba = self.predict_proba(X=X)\n",
        "        return np.argmax(pred_proba, axis=1)\n",
        "\n",
        "    def mg_scanning(self, X, y=None):\n",
        "        self._n_samples = X.shape[0]\n",
        "        shape_1X = self.shape_1X\n",
        "        if isinstance(shape_1X, int):\n",
        "            shape_1X = [1, shape_1X]\n",
        "        if not self.window:\n",
        "            self.window = [shape_1X[1]]\n",
        "        mgs_pred_prob = []\n",
        "        for wdw_size in self.window:\n",
        "            wdw_pred_prob = self._window_slicing_pred_prob(X, wdw_size, shape_1X, y=y)\n",
        "            mgs_pred_prob.append(wdw_pred_prob)\n",
        "        return np.concatenate(mgs_pred_prob, axis=1)\n",
        "\n",
        "    def _window_slicing_pred_prob(self, X, window, shape_1X, y=None):\n",
        "        if shape_1X[0] > 1:\n",
        "            sliced_X, sliced_y = self._window_slicing_img(X, window, shape_1X, y=y, stride=self.stride)\n",
        "        else:\n",
        "            sliced_X, sliced_y = self._window_slicing_sequence(X, window, shape_1X, y=y, stride=self.stride)\n",
        "        if y is not None:\n",
        "            prf = RandomForestClassifier(n_estimators=self.n_mgsRFtree, max_features='sqrt', min_samples_split=self.min_samples_mgs, oob_score=True, n_jobs=self.n_jobs)\n",
        "            crf = RandomForestClassifier(n_estimators=self.n_mgsRFtree, max_features=1, min_samples_split=self.min_samples_mgs, oob_score=True, n_jobs=self.n_jobs)\n",
        "            prf.fit(sliced_X, sliced_y)\n",
        "            crf.fit(sliced_X, sliced_y)\n",
        "            setattr(self, f'_mgsprf_{window}', prf)\n",
        "            setattr(self, f'_mgscrf_{window}', crf)\n",
        "            pred_prob_prf = prf.oob_decision_function_\n",
        "            pred_prob_crf = crf.oob_decision_function_\n",
        "        else:\n",
        "            prf = getattr(self, f'_mgsprf_{window}')\n",
        "            crf = getattr(self, f'_mgscrf_{window}')\n",
        "            pred_prob_prf = prf.predict_proba(sliced_X)\n",
        "            pred_prob_crf = crf.predict_proba(sliced_X)\n",
        "        pred_prob = np.c_[pred_prob_prf, pred_prob_crf]\n",
        "        return pred_prob.reshape([self._n_samples, -1])\n",
        "\n",
        "    def _window_slicing_sequence(self, X, window, shape_1X, y=None, stride=1):\n",
        "        if shape_1X[1] < window:\n",
        "            raise ValueError('window must be smaller than the sequence dimension')\n",
        "        len_iter = (shape_1X[1] - window) // stride + 1\n",
        "        iter_array = np.arange(0, stride * len_iter, stride)\n",
        "        inds_to_take = [np.arange(i, i + window) for i in iter_array]\n",
        "        sliced_X = np.take(X, inds_to_take, axis=1).reshape(-1, window)\n",
        "        if y is not None:\n",
        "            sliced_y = np.repeat(y, len_iter)\n",
        "        else:\n",
        "            sliced_y = None\n",
        "        return sliced_X, sliced_y\n",
        "\n",
        "    def cascade_forest(self, X, y=None):\n",
        "        if y is not None:\n",
        "            self.n_layer = 0\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.cascade_test_size)\n",
        "            self.n_layer += 1\n",
        "            prf_crf_pred_ref = self._cascade_layer(X_train, y_train)\n",
        "            accuracy_ref = self._cascade_evaluation(X_test, y_test)\n",
        "            feat_arr = self._create_feat_arr(X_train, prf_crf_pred_ref)\n",
        "            self.n_layer += 1\n",
        "            prf_crf_pred_layer = self._cascade_layer(feat_arr, y_train)\n",
        "            accuracy_layer = self._cascade_evaluation(X_test, y_test)\n",
        "            while accuracy_layer > (accuracy_ref + self.tolerance) and self.n_layer <= self.cascade_layer:\n",
        "                accuracy_ref = accuracy_layer\n",
        "                prf_crf_pred_ref = prf_crf_pred_layer\n",
        "                feat_arr = self._create_feat_arr(X_train, prf_crf_pred_ref)\n",
        "                self.n_layer += 1\n",
        "                prf_crf_pred_layer = self._cascade_layer(feat_arr, y_train)\n",
        "                accuracy_layer = self._cascade_evaluation(X_test, y_test)\n",
        "            if accuracy_layer < accuracy_ref:\n",
        "                for irf in range(self.n_cascadeRF):\n",
        "                    delattr(self, f'_casprf{self.n_layer}_{irf}')\n",
        "                    delattr(self, f'_cascrf{self.n_layer}_{irf}')\n",
        "                self.n_layer -= 1\n",
        "        else:\n",
        "            at_layer = 1\n",
        "            prf_crf_pred_ref = self._cascade_layer(X, layer=at_layer)\n",
        "            while at_layer < self.n_layer:\n",
        "                at_layer += 1\n",
        "                feat_arr = self._create_feat_arr(X, prf_crf_pred_ref)\n",
        "                prf_crf_pred_ref = self._cascade_layer(feat_arr, layer=at_layer)\n",
        "        return prf_crf_pred_ref\n",
        "\n",
        "    def _cascade_layer(self, X, y=None, layer=0):\n",
        "        prf = RandomForestClassifier(n_estimators=self.n_cascadeRFtree, max_features='sqrt', min_samples_split=self.min_samples_cascade, oob_score=True, n_jobs=self.n_jobs)\n",
        "        crf = RandomForestClassifier(n_estimators=self.n_cascadeRFtree, max_features=1, min_samples_split=self.min_samples_cascade, oob_score=True, n_jobs=self.n_jobs)\n",
        "        prf_crf_pred = []\n",
        "        if y is not None:\n",
        "            for irf in range(self.n_cascadeRF):\n",
        "                prf.fit(X, y)\n",
        "                crf.fit(X, y)\n",
        "                setattr(self, f'_casprf{self.n_layer}_{irf}', prf)\n",
        "                setattr(self, f'_cascrf{self.n_layer}_{irf}', crf)\n",
        "                prf_crf_pred.append(prf.oob_decision_function_)\n",
        "                prf_crf_pred.append(crf.oob_decision_function_)\n",
        "        else:\n",
        "            for irf in range(self.n_cascadeRF):\n",
        "                prf = getattr(self, f'_casprf{layer}_{irf}')\n",
        "                crf = getattr(self, f'_cascrf{layer}_{irf}')\n",
        "                prf_crf_pred.append(prf.predict_proba(X))\n",
        "                prf_crf_pred.append(crf.predict_proba(X))\n",
        "        return prf_crf_pred\n",
        "\n",
        "\n",
        "    def _cascade_evaluation(self, X_test, y_test):\n",
        "        casc_pred_prob = np.mean(self.cascade_forest(X_test), axis=0)\n",
        "        casc_pred = np.argmax(casc_pred_prob, axis=1)\n",
        "        return accuracy_score(y_true=y_test, y_pred=casc_pred)\n",
        "\n",
        "    def _create_feat_arr(self, X, prf_crf_pred):\n",
        "        swap_pred = np.swapaxes(prf_crf_pred, 0, 1)\n",
        "        add_feat = swap_pred.reshape([X.shape[0], -1])\n",
        "        return np.concatenate([add_feat, X], axis=1)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {'shape_1X': self.shape_1X,\n",
        "                'n_mgsRFtree': self.n_mgsRFtree,\n",
        "                'window': self.window,\n",
        "                'stride': self.stride,\n",
        "                'cascade_test_size': self.cascade_test_size,\n",
        "                'n_cascadeRF': self.n_cascadeRF,\n",
        "                'n_cascadeRFtree': self.n_cascadeRFtree,\n",
        "                'cascade_layer': self.cascade_layer,\n",
        "                'min_samples_mgs': self.min_samples_mgs,\n",
        "                'min_samples_cascade': self.min_samples_cascade,\n",
        "                'tolerance': self.tolerance,\n",
        "                'n_jobs': self.n_jobs,\n",
        "                'use_mg_scanning': self.use_mg_scanning}\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOoFBhuzs7g4"
      },
      "outputs": [],
      "source": [
        "import wfdb\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "AAMI_CLASSES = {\n",
        "    'N': 0, 'L': 0, 'R': 0, 'e': 0, 'j': 0,\n",
        "    'A': 1, 'a': 1, 'J': 1, 'S': 1,\n",
        "    'V': 2, 'E': 2,\n",
        "    'F': 3,\n",
        "    '/': 4, 'f': 4, 'Q': 4,\n",
        "}\n",
        "\n",
        "def get_aami_class(symbol):\n",
        "    return AAMI_CLASSES.get(symbol)\n",
        "\n",
        "def apply_bandpass_filter(signal, fs=360):\n",
        "    lowcut = 0.5\n",
        "    highcut = 45.0\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(2, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "def segment_heartbeats(signal, annotations, fs=360, window_size=360):\n",
        "    heartbeats, labels = [], []\n",
        "    window_before = window_size // 2\n",
        "    window_after = window_size - window_before\n",
        "    for i, symbol in enumerate(annotations.symbol):\n",
        "        aami_class = get_aami_class(symbol)\n",
        "        if aami_class is not None:\n",
        "            peak_sample = annotations.sample[i]\n",
        "            start, end = peak_sample - window_before, peak_sample + window_after\n",
        "            if start >= 0 and end < len(signal):\n",
        "                heartbeats.append(signal[start:end])\n",
        "                labels.append(aami_class)\n",
        "    return np.array(heartbeats), np.array(labels)\n",
        "\n",
        "def preprocess_data(data_path, window_size=360, max_records=None):\n",
        "    print(f\"Starting data preprocessing...\")\n",
        "    record_names = sorted([f.split('.')[0] for f in os.listdir(data_path) if f.endswith('.hea')])\n",
        "    all_heartbeats, all_labels = [], []\n",
        "    for i, record_name in enumerate(record_names):\n",
        "        if max_records and i >= max_records:\n",
        "            break\n",
        "        try:\n",
        "            record = wfdb.rdrecord(os.path.join(data_path, record_name))\n",
        "            annotations = wfdb.rdann(os.path.join(data_path, record_name), 'atr')\n",
        "            signal = record.p_signal[:, record.sig_name.index('MLII') if 'MLII' in record.sig_name else 0]\n",
        "            filtered_signal = apply_bandpass_filter(signal, fs=record.fs)\n",
        "            heartbeats, labels = segment_heartbeats(filtered_signal, annotations, fs=record.fs, window_size=window_size)\n",
        "            all_heartbeats.append(heartbeats)\n",
        "            all_labels.append(labels)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process record {record_name}: {e}\")\n",
        "    if not all_heartbeats:\n",
        "        raise ValueError(\"No heartbeats processed. Check data path and file integrity.\")\n",
        "    X, y = np.concatenate(all_heartbeats), np.concatenate(all_labels)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    print(\"Applying SMOTE to balance the training data...\")\n",
        "    smote = SMOTE(random_state=42, k_neighbors=1) # Reduced k_neighbors to handle small classes\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "    print(f\"Original training samples: {len(y_train)}, Resampled training samples: {len(y_train_resampled)}\")\n",
        "    print(\"Data preprocessing complete.\")\n",
        "    return X_train_resampled, X_test, y_train_resampled, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcXWtPZCs7g5"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pywt\n",
        "\n",
        "def extract_features(train_data, test_data, method='MFCC'):\n",
        "    print(f\"Extracting features using {method} method...\")\n",
        "    if method == 'MFCC':\n",
        "        train_features = _extract_mfcc(train_data)\n",
        "        test_features = _extract_mfcc(test_data)\n",
        "    elif method == 'DWT':\n",
        "        train_features = _extract_dwt(train_data)\n",
        "        test_features = _extract_dwt(test_data)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown feature extraction method: {method}\")\n",
        "    print(\"Feature extraction complete.\")\n",
        "    return train_features, test_features\n",
        "\n",
        "def _extract_mfcc(data, sr=360, n_mfcc=13):\n",
        "    mfccs = [np.mean(librosa.feature.mfcc(y=heartbeat.astype(float), sr=sr, n_mfcc=n_mfcc, n_fft=2048).T, axis=0) for heartbeat in data]\n",
        "    return np.array(mfccs)\n",
        "\n",
        "def _extract_dwt(data, wavelet='db4', level=4):\n",
        "    coeffs = [pywt.wavedec(heartbeat, wavelet, level=level) for heartbeat in data]\n",
        "    flat_features = [np.concatenate([c.flatten() for c in coef]) for coef in coeffs]\n",
        "    max_len = max(len(f) for f in flat_features)\n",
        "    padded_features = np.array([np.pad(f, (0, max_len - len(f))) for f in flat_features])\n",
        "    return padded_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1s5yOuRs7g5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "def train_and_evaluate(train_features, train_labels, test_features, test_labels, model_type='gcForest'):\n",
        "    print(f\"--- Training and evaluating {model_type} model ---\")\n",
        "    if model_type == 'CascadeForest':\n",
        "        param_grid = {\n",
        "            'n_cascadeRFtree': [101, 151], 'n_cascadeRF': [2],\n",
        "            'min_samples_cascade': [0.05, 0.1], 'cascade_layer': [15, 25], 'tolerance': [0.005]\n",
        "        }\n",
        "        model_base = gcForest(use_mg_scanning=False, n_jobs=-1)\n",
        "    elif model_type == 'gcForest':\n",
        "        feature_dim = train_features.shape[1]\n",
        "        param_grid = {\n",
        "            'window': [[int(feature_dim * 0.2)], [int(feature_dim * 0.3)]], 'n_mgsRFtree': [30],\n",
        "            'n_cascadeRFtree': [101], 'n_cascadeRF': [2], 'cascade_layer': [15], 'tolerance': [0.005]\n",
        "        }\n",
        "        model_base = gcForest(shape_1X=train_features.shape[1], n_jobs=-1)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model type: {model_type}\")\n",
        "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(estimator=model_base, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "    grid_search.fit(train_features, train_labels)\n",
        "    print(f\"Best parameters for {model_type}: {grid_search.best_params_}\")\n",
        "    model = grid_search.best_estimator_\n",
        "    print(\"Evaluating the best model on the test set...\")\n",
        "    predictions = model.predict(test_features)\n",
        "    probas = model.predict_proba(test_features)\n",
        "    print(f\"Accuracy: {accuracy_score(test_labels, predictions):.4f}\")\n",
        "    print(f\"F1-score: {f1_score(test_labels, predictions, average='weighted'):.4f}\")\n",
        "    print(f\"Precision: {precision_score(test_labels, predictions, average='weighted'):.4f}\")\n",
        "    print(f\"Recall: {recall_score(test_labels, predictions, average='weighted'):.4f}\")\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(test_labels, probas, multi_class='ovr', average='weighted')\n",
        "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Could not compute ROC AUC Score: {e}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(test_labels, predictions))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7C8QER7s7g5"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def explain_model(model, test_features, feature_names, output_path):\n",
        "    print(\"Calculating SHAP values...\")\n",
        "    try:\n",
        "        background_data = shap.sample(test_features, 100)\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, background_data)\n",
        "        shap_values = explainer.shap_values(test_features)\n",
        "        print(\"Generating SHAP summary plot...\")\n",
        "        plt.figure()\n",
        "        if isinstance(shap_values, list):\n",
        "            shap.summary_plot(shap_values[0], test_features, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "        else:\n",
        "            shap.summary_plot(shap_values, test_features, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "        plt.title(\"SHAP Feature Importance\")\n",
        "        plot_file = os.path.join(output_path, 'shap_summary_plot.png')\n",
        "        plt.savefig(plot_file)\n",
        "        plt.close()\n",
        "        print(f\"SHAP summary plot saved to {plot_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate SHAP plot: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXx1gT1s7g6"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "def run_experiment(args):\n",
        "    print(f\"====================--- Starting Experiment: Model={args.model}, Features={args.feature_extractor} ---\")\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(args.data_path, max_records=args.max_records)\n",
        "    train_features, test_features = extract_features(X_train, X_test, method=args.feature_extractor)\n",
        "    model = train_and_evaluate(train_features, y_train, test_features, y_test, model_type=args.model)\n",
        "    if args.explain:\n",
        "        feature_names = [f'MFCC_{i}' for i in range(train_features.shape[1])] if args.feature_extractor == 'MFCC' else [f'DWT_{i}' for i in range(train_features.shape[1]) ]\n",
        "        explain_model(model, test_features, feature_names, args.output_path)\n",
        "    print(f\"--- Experiment Finished: Model={args.model} ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSJBF8v8s7g6"
      },
      "source": [
        "## 4. Run Experiments\n",
        "\n",
        "Now we can run the experiments for both model types. We use a small number of records (`max_records=4`) for a quick test run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604,
          "referenced_widgets": [
            "d19fe35244d54ca4b1cc99470a6a19cc",
            "b56dd29c0a76461fb8331bb08d90dbde",
            "4f65ed5f9ecf43d894908fbdd2ba8a0e",
            "73027e0125044690bbbd738adeedc95f",
            "94e060259f094a0b8c4e6c2db2147f77",
            "7196331b3b0e4d3db45847a6ced2e882",
            "8ea5651b878744b48f30343ff00c51aa",
            "a31245b0023e43abb3e0ca07aa8baf38",
            "d41a931fc3044323b63ae459b037a06e",
            "d93f99c08ebf4cceb2b45abd23ad1124",
            "f523ce6b16d34ea09a4c8e20098df3ff"
          ]
        },
        "id": "fGxGaNSns7g6",
        "outputId": "dd4cb4fb-69ea-4e91-b677-618f70f4ed67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================--- Starting Experiment: Model=CascadeForest, Features=MFCC ---\n",
            "Starting data preprocessing...\n",
            "Applying SMOTE to balance the training data...\n",
            "Original training samples: 6722, Resampled training samples: 20084\n",
            "Data preprocessing complete.\n",
            "Extracting features using MFCC method...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=360\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete.\n",
            "--- Training and evaluating CascadeForest model ---\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Best parameters for CascadeForest: {'cascade_layer': 15, 'min_samples_cascade': 0.05, 'n_cascadeRF': 2, 'n_cascadeRFtree': 101, 'tolerance': 0.005}\n",
            "Evaluating the best model on the test set...\n",
            "Accuracy: 0.7210\n",
            "F1-score: 0.7312\n",
            "Precision: 0.7435\n",
            "Recall: 0.7210\n",
            "ROC AUC Score: 0.9967\n",
            "Confusion Matrix:\n",
            "[[1207   46    2    0    0]\n",
            " [   4    4    0    0    0]\n",
            " [   0    0    1    0    0]\n",
            " [   0    0    0    0    0]\n",
            " [   2    0    0  415    0]]\n",
            "Calculating SHAP values...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1681 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d19fe35244d54ca4b1cc99470a6a19cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import argparse\n",
        "\n",
        "args_cascade = argparse.Namespace(\n",
        "    data_path=DATA_PATH,\n",
        "    output_path=OUTPUT_PATH,\n",
        "    feature_extractor='MFCC',\n",
        "    model='CascadeForest',\n",
        "    explain=True,\n",
        "    max_records=4\n",
        ")\n",
        "run_experiment(args_cascade)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dP7226sWzbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRSxUb8hs7g6"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "args_gc = argparse.Namespace(\n",
        "    data_path=DATA_PATH,\n",
        "    output_path=OUTPUT_PATH,\n",
        "    feature_extractor='DWT',\n",
        "    model='gcForest',\n",
        "    explain=True,\n",
        "    max_records=4\n",
        ")\n",
        "run_experiment(args_gc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q64zgZROs7g6"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "If the cells above executed without errors, your environment is correctly set up and the self-contained experiment notebook is working. You can now adjust the parameters (e.g., `max_records`, `feature_extractor`, and the `param_grid` in the `train_and_evaluate` function) to run your full research experiments."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deepforest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d19fe35244d54ca4b1cc99470a6a19cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b56dd29c0a76461fb8331bb08d90dbde",
              "IPY_MODEL_4f65ed5f9ecf43d894908fbdd2ba8a0e",
              "IPY_MODEL_73027e0125044690bbbd738adeedc95f"
            ],
            "layout": "IPY_MODEL_94e060259f094a0b8c4e6c2db2147f77"
          }
        },
        "b56dd29c0a76461fb8331bb08d90dbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7196331b3b0e4d3db45847a6ced2e882",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea5651b878744b48f30343ff00c51aa",
            "value": "  6%"
          }
        },
        "4f65ed5f9ecf43d894908fbdd2ba8a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31245b0023e43abb3e0ca07aa8baf38",
            "max": 1681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d41a931fc3044323b63ae459b037a06e",
            "value": 101
          }
        },
        "73027e0125044690bbbd738adeedc95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93f99c08ebf4cceb2b45abd23ad1124",
            "placeholder": "​",
            "style": "IPY_MODEL_f523ce6b16d34ea09a4c8e20098df3ff",
            "value": " 101/1681 [10:12&lt;3:00:17,  6.85s/it]"
          }
        },
        "94e060259f094a0b8c4e6c2db2147f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7196331b3b0e4d3db45847a6ced2e882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea5651b878744b48f30343ff00c51aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a31245b0023e43abb3e0ca07aa8baf38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41a931fc3044323b63ae459b037a06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d93f99c08ebf4cceb2b45abd23ad1124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f523ce6b16d34ea09a4c8e20098df3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}